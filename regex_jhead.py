#!/usr/bin/env python

#This code gets the original source photos for each image id in url.txt. "url.txt" is  generated by a script that crawls flickr by tag. Each image in the crawler is returned as a medium size image by default. 

import urllib
import  os,sys
import re
import  flickrapi


api_key = '005b8c46e4020bd2639342676d41cfcc'  
api_secret = '95940c26dc30095f'  

flickr = flickrapi.FlickrAPI(api_key,api_secret)

textfile = open('url.txt')
filetext = textfile.read()
textfile.close()

#1. find all 10-11 digits (picture ids)in text file
matches = re.findall('\d{10,11}',filetext)
      
#2. regex extract url ids
for photo in matches:
     url = flickr.photos_getSizes(photo_id=photo).getiterator('size')[-1].attrib['source']

     filename = '%s.'%photo + url.split('.')[-1].split('?')[0]

     urllib.urlretrieve(url, filename)

     tags = flickr.photos_getExif(photo_id=photo).getiterator('exif')

     with open('tags.xml', 'w') as tags_file:
         tags_file.write("<?xml version='1.0' encoding='UTF-8'?>\n<rdf:RDF xmlns:rdf='http://www.w3.org/1999/02/22-rdf-syntax-ns#'>\n")
         for tag in tags:
             tags_file.write('<%s:%s>%s</%s:%s>\n'%(tag.attrib['tagspace'], tag.attrib['tag'], tag.getchildren()[0].text.strip().encode('utf-8'), tag.attrib['tagspace'], tag.attrib['tag']))
         tags_file.write('</rdf:RDF>\n')

     os.system('exiftool -overwrite_original -tagsfromfile tags.xml %s'%filename)

os.remove('tags.xml')


#3. jhead on each output










